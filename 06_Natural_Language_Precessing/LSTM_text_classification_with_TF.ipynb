{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Messages Classification using LSTM, Bi-LSTM, and GRU\n",
    "- Author: Nuzulul Khairu Nissa\n",
    "- Link: https://nzlul.medium.com/the-classification-of-text-messages-using-lstm-bi-lstm-and-gru-f79b207f90ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load, explore and plot data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Text pre-processing\n",
    "\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/sms_spam.csv', sep='\\t', names=['label', 'message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">message</th>\n",
       "      <th>count</th>\n",
       "      <td>4825</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4516</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                              ham  \\\n",
       "message count                     4825   \n",
       "        unique                    4516   \n",
       "        top     Sorry, I'll call later   \n",
       "        freq                        30   \n",
       "\n",
       "label                                                        spam  \n",
       "message count                                                 747  \n",
       "        unique                                                653  \n",
       "        top     Please call our customer service representativ...  \n",
       "        freq                                                    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  msg_type\n",
       "0   ham  Go until jurong point, crazy.. Available only ...         0\n",
       "1   ham                      Ok lar... Joking wif u oni...         0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...         1\n",
       "3   ham  U dun say so early hor... U c already then say...         0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['msg_type'] = df['label'].map({'ham':0, 'spam':1})\n",
    "\n",
    "df_label = df['msg_type'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,)\n",
      "(1115,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['message'], df_label, test_size=0.2, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: message, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_len = 50 \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>' # out of vocabulary token\n",
    "vocab_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, \n",
    "                      char_level = False,\n",
    "                      oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the word_index\n",
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence and padding\n",
    "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "training_padded = pad_sequences(training_sequences,\n",
    "                                maxlen = max_len,\n",
    "                                padding = padding_type,\n",
    "                                truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "testing_padded = pad_sequences(testing_sequences,\n",
    "                               maxlen = max_len,\n",
    "                               padding = padding_type,\n",
    "                               truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training tensor:  (4457, 50)\n",
      "Shape of testing tensor:  (1115, 50)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training tensor: ', training_padded.shape)\n",
    "print('Shape of testing tensor: ', testing_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameter\n",
    "vocab_size = 500 \n",
    "embedding_dim = 16\n",
    "drop_value = 0.2\n",
    "n_dense = 24\n",
    "\n",
    "# Define Dense Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,\n",
    "                    embedding_dim,\n",
    "                    input_length = max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dropout(drop_value))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 16)            8000      \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                408       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8433 (32.94 KB)\n",
      "Trainable params: 8433 (32.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "140/140 - 1s - loss: 0.5012 - accuracy: 0.8654 - val_loss: 0.3368 - val_accuracy: 0.8664 - 807ms/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "140/140 - 0s - loss: 0.2965 - accuracy: 0.8658 - val_loss: 0.2424 - val_accuracy: 0.8664 - 186ms/epoch - 1ms/step\n",
      "Epoch 3/30\n",
      "140/140 - 0s - loss: 0.2025 - accuracy: 0.9085 - val_loss: 0.1662 - val_accuracy: 0.9462 - 188ms/epoch - 1ms/step\n",
      "Epoch 4/30\n",
      "140/140 - 0s - loss: 0.1410 - accuracy: 0.9598 - val_loss: 0.1156 - val_accuracy: 0.9614 - 187ms/epoch - 1ms/step\n",
      "Epoch 5/30\n",
      "140/140 - 0s - loss: 0.1047 - accuracy: 0.9702 - val_loss: 0.0835 - val_accuracy: 0.9758 - 186ms/epoch - 1ms/step\n",
      "Epoch 6/30\n",
      "140/140 - 0s - loss: 0.0782 - accuracy: 0.9749 - val_loss: 0.0686 - val_accuracy: 0.9839 - 185ms/epoch - 1ms/step\n",
      "Epoch 7/30\n",
      "140/140 - 0s - loss: 0.0670 - accuracy: 0.9809 - val_loss: 0.0568 - val_accuracy: 0.9848 - 189ms/epoch - 1ms/step\n",
      "Epoch 8/30\n",
      "140/140 - 0s - loss: 0.0588 - accuracy: 0.9814 - val_loss: 0.0518 - val_accuracy: 0.9883 - 187ms/epoch - 1ms/step\n",
      "Epoch 9/30\n",
      "140/140 - 0s - loss: 0.0531 - accuracy: 0.9850 - val_loss: 0.0480 - val_accuracy: 0.9883 - 188ms/epoch - 1ms/step\n",
      "Epoch 10/30\n",
      "140/140 - 0s - loss: 0.0475 - accuracy: 0.9843 - val_loss: 0.0454 - val_accuracy: 0.9892 - 192ms/epoch - 1ms/step\n",
      "Epoch 11/30\n",
      "140/140 - 0s - loss: 0.0443 - accuracy: 0.9854 - val_loss: 0.0449 - val_accuracy: 0.9901 - 191ms/epoch - 1ms/step\n",
      "Epoch 12/30\n",
      "140/140 - 0s - loss: 0.0412 - accuracy: 0.9863 - val_loss: 0.0431 - val_accuracy: 0.9901 - 205ms/epoch - 1ms/step\n",
      "Epoch 13/30\n",
      "140/140 - 0s - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0427 - val_accuracy: 0.9910 - 186ms/epoch - 1ms/step\n",
      "Epoch 14/30\n",
      "140/140 - 0s - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.0424 - val_accuracy: 0.9910 - 184ms/epoch - 1ms/step\n",
      "Epoch 15/30\n",
      "140/140 - 0s - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.0435 - val_accuracy: 0.9910 - 182ms/epoch - 1ms/step\n",
      "Epoch 16/30\n",
      "140/140 - 0s - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0431 - val_accuracy: 0.9910 - 186ms/epoch - 1ms/step\n",
      "Epoch 17/30\n",
      "140/140 - 0s - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.0430 - val_accuracy: 0.9892 - 180ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(training_padded,\n",
    "                    y_train,\n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, y_test),\n",
    "                    callbacks =[early_stop],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 749us/step - loss: 0.0430 - accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04302380979061127, 0.9892376661300659]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testing_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - loss: 0.0263 - accuracy: 0.9906 - 48ms/epoch - 3ms/step\n",
      "5/5 - 0s - loss: 0.0430 - accuracy: 0.9892 - 23ms/epoch - 5ms/step\n",
      "Train accuracy: 99.06\n",
      "Valid accuracy: 98.92\n"
     ]
    }
   ],
   "source": [
    "train_dense_results = model.evaluate(training_padded, np.asarray(y_train), verbose=2, batch_size=256)\n",
    "valid_dense_results = model.evaluate(testing_padded, np.asarray(y_test), verbose=2, batch_size=256)\n",
    "print(f'Train accuracy: {train_dense_results[1]*100:0.2f}')\n",
    "print(f'Valid accuracy: {valid_dense_results[1]*100:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LSTM model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter\n",
    "n_lstm = 128\n",
    "drop_lstm = 0.2\n",
    "# Define LSTM Model \n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model1.add(SpatialDropout1D(drop_lstm))\n",
    "model1.add(LSTM(n_lstm, return_sequences=False))\n",
    "model1.add(Dropout(drop_lstm))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 16)            8000      \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 50, 16)            0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               74240     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82369 (321.75 KB)\n",
      "Trainable params: 82369 (321.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "140/140 - 5s - loss: 0.2232 - accuracy: 0.9278 - val_loss: 0.2200 - val_accuracy: 0.8834 - 5s/epoch - 33ms/step\n",
      "Epoch 2/30\n",
      "140/140 - 3s - loss: 0.0943 - accuracy: 0.9713 - val_loss: 0.0763 - val_accuracy: 0.9812 - 3s/epoch - 21ms/step\n",
      "Epoch 3/30\n",
      "140/140 - 3s - loss: 0.0785 - accuracy: 0.9807 - val_loss: 0.0487 - val_accuracy: 0.9874 - 3s/epoch - 21ms/step\n",
      "Epoch 4/30\n",
      "140/140 - 3s - loss: 0.0762 - accuracy: 0.9809 - val_loss: 0.1655 - val_accuracy: 0.9552 - 3s/epoch - 21ms/step\n",
      "Epoch 5/30\n",
      "140/140 - 3s - loss: 0.0711 - accuracy: 0.9816 - val_loss: 0.0684 - val_accuracy: 0.9740 - 3s/epoch - 22ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "history = model1.fit(training_padded,\n",
    "                     y_train,\n",
    "                     epochs=num_epochs, \n",
    "                     validation_data=(testing_padded, y_test),\n",
    "                     callbacks =[early_stop],\n",
    "                     verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 1s - loss: 0.0666 - accuracy: 0.9787 - 564ms/epoch - 31ms/step\n",
      "5/5 - 0s - loss: 0.0684 - accuracy: 0.9740 - 166ms/epoch - 33ms/step\n",
      "Train accuracy: 97.87\n",
      "Valid accuracy: 97.40\n"
     ]
    }
   ],
   "source": [
    "train_dense_results = model1.evaluate(training_padded, np.asarray(y_train), verbose=2, batch_size=256)\n",
    "valid_dense_results = model1.evaluate(testing_padded, np.asarray(y_test), verbose=2, batch_size=256)\n",
    "print(f'Train accuracy: {train_dense_results[1]*100:0.2f}')\n",
    "print(f'Valid accuracy: {valid_dense_results[1]*100:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     input_length = max_len))\n",
    "model2.add(Bidirectional(LSTM(n_lstm,\n",
    "                              return_sequences = False)))\n",
    "model2.add(Dropout(drop_lstm))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 16)            8000      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               148480    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156737 (612.25 KB)\n",
      "Trainable params: 156737 (612.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "140/140 - 5s - loss: 0.1965 - accuracy: 0.9329 - val_loss: 0.0774 - val_accuracy: 0.9776 - 5s/epoch - 36ms/step\n",
      "Epoch 2/30\n",
      "140/140 - 3s - loss: 0.0653 - accuracy: 0.9782 - val_loss: 0.0639 - val_accuracy: 0.9803 - 3s/epoch - 20ms/step\n",
      "Epoch 3/30\n",
      "140/140 - 3s - loss: 0.0559 - accuracy: 0.9838 - val_loss: 0.0476 - val_accuracy: 0.9874 - 3s/epoch - 19ms/step\n",
      "Epoch 4/30\n",
      "140/140 - 3s - loss: 0.0502 - accuracy: 0.9872 - val_loss: 0.0478 - val_accuracy: 0.9865 - 3s/epoch - 19ms/step\n",
      "Epoch 5/30\n",
      "140/140 - 3s - loss: 0.0519 - accuracy: 0.9850 - val_loss: 0.0415 - val_accuracy: 0.9892 - 3s/epoch - 20ms/step\n",
      "Epoch 6/30\n",
      "140/140 - 3s - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0566 - val_accuracy: 0.9839 - 3s/epoch - 20ms/step\n",
      "Epoch 7/30\n",
      "140/140 - 3s - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0514 - val_accuracy: 0.9874 - 3s/epoch - 20ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor = 'val_loss',\n",
    "                           patience = 2)\n",
    "history = model2.fit(training_padded,\n",
    "                     y_train,\n",
    "                     epochs = num_epochs,\n",
    "                     validation_data = (testing_padded, y_test),\n",
    "                     callbacks = [early_stop],\n",
    "                     verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 1s - loss: 0.0333 - accuracy: 0.9921 - 551ms/epoch - 31ms/step\n",
      "5/5 - 0s - loss: 0.0514 - accuracy: 0.9874 - 148ms/epoch - 30ms/step\n",
      "Train accuracy: 99.21\n",
      "Valid accuracy: 98.74\n"
     ]
    }
   ],
   "source": [
    "train_dense_results = model2.evaluate(training_padded, np.asarray(y_train), verbose=2, batch_size=256)\n",
    "valid_dense_results = model2.evaluate(testing_padded, np.asarray(y_test), verbose=2, batch_size=256)\n",
    "print(f'Train accuracy: {train_dense_results[1]*100:0.2f}')\n",
    "print(f'Valid accuracy: {valid_dense_results[1]*100:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     input_length = max_len))\n",
    "model3.add(SpatialDropout1D(0.2))\n",
    "model3.add(GRU(128, return_sequences = False))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 50, 16)            8000      \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spati  (None, 50, 16)            0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               56064     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64193 (250.75 KB)\n",
      "Trainable params: 64193 (250.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss = 'binary_crossentropy',\n",
    "                       optimizer = 'adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "140/140 - 4s - loss: 0.4282 - accuracy: 0.8613 - val_loss: 0.3943 - val_accuracy: 0.8664 - 4s/epoch - 28ms/step\n",
      "Epoch 2/30\n",
      "140/140 - 2s - loss: 0.3977 - accuracy: 0.8658 - val_loss: 0.3969 - val_accuracy: 0.8664 - 2s/epoch - 17ms/step\n",
      "Epoch 3/30\n",
      "140/140 - 2s - loss: 0.3817 - accuracy: 0.8665 - val_loss: 0.1566 - val_accuracy: 0.9623 - 2s/epoch - 17ms/step\n",
      "Epoch 4/30\n",
      "140/140 - 2s - loss: 0.0865 - accuracy: 0.9769 - val_loss: 0.0459 - val_accuracy: 0.9919 - 2s/epoch - 17ms/step\n",
      "Epoch 5/30\n",
      "140/140 - 2s - loss: 0.0542 - accuracy: 0.9847 - val_loss: 0.0412 - val_accuracy: 0.9892 - 2s/epoch - 17ms/step\n",
      "Epoch 6/30\n",
      "140/140 - 2s - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.0371 - val_accuracy: 0.9910 - 2s/epoch - 16ms/step\n",
      "Epoch 7/30\n",
      "140/140 - 2s - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0407 - val_accuracy: 0.9910 - 2s/epoch - 16ms/step\n",
      "Epoch 8/30\n",
      "140/140 - 2s - loss: 0.0330 - accuracy: 0.9917 - val_loss: 0.0361 - val_accuracy: 0.9910 - 2s/epoch - 16ms/step\n",
      "Epoch 9/30\n",
      "140/140 - 2s - loss: 0.0286 - accuracy: 0.9930 - val_loss: 0.0474 - val_accuracy: 0.9901 - 2s/epoch - 17ms/step\n",
      "Epoch 10/30\n",
      "140/140 - 2s - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.0462 - val_accuracy: 0.9901 - 2s/epoch - 16ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "history = model3.fit(training_padded,\n",
    "                     y_train,\n",
    "                     epochs=num_epochs, \n",
    "                     validation_data=(testing_padded, y_test),\n",
    "                     callbacks =[early_stop],\n",
    "                     verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - loss: 0.0184 - accuracy: 0.9957 - 403ms/epoch - 22ms/step\n",
      "5/5 - 0s - loss: 0.0462 - accuracy: 0.9901 - 113ms/epoch - 23ms/step\n",
      "Train accuracy: 99.57\n",
      "Valid accuracy: 99.01\n"
     ]
    }
   ],
   "source": [
    "train_dense_results = model3.evaluate(training_padded, np.asarray(y_train), verbose=2, batch_size=256)\n",
    "valid_dense_results = model3.evaluate(testing_padded, np.asarray(y_test), verbose=2, batch_size=256)\n",
    "print(f'Train accuracy: {train_dense_results[1]*100:0.2f}')\n",
    "print(f'Valid accuracy: {valid_dense_results[1]*100:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the four different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 794us/step - loss: 0.0430 - accuracy: 0.9892\n",
      "Dense model loss and accuracy: [0.04302380979061127, 0.9892376661300659] \n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0684 - accuracy: 0.9740\n",
      "LSTM model loss and accuracy: [0.06843268126249313, 0.9739910364151001] \n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9874\n",
      "Bi-LSTM model loss and accuracy: [0.05136081948876381, 0.9874439239501953] \n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9901\n",
      "GRU model loss and accuracy: [0.04619617387652397, 0.9901345372200012]\n"
     ]
    }
   ],
   "source": [
    "# Comparing the four different models\n",
    "print(f\"Dense model loss and accuracy: {model.evaluate(testing_padded, y_test)} \" )\n",
    "print(f\"LSTM model loss and accuracy: {model1.evaluate(testing_padded, y_test)} \" )\n",
    "print(f\"Bi-LSTM model loss and accuracy: {model2.evaluate(testing_padded, y_test)} \" )\n",
    "print(f\"GRU model loss and accuracy: {model3.evaluate(testing_padded, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Ham or Spam for the new messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "       \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\",\n",
       "       'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
       "       'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',\n",
       "       'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info',\n",
       "       'URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18',\n",
       "       'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL',\n",
       "       'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+',\n",
       "       'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged',\n",
       "       '07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['msg_type']==1]['message'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32852173],\n",
       "       [0.00537429],\n",
       "       [0.9997755 ],\n",
       "       [0.9550846 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_msg = [\n",
    "  \"Have friends and colleagues who could benefit from these weekly updates? Send them to this link to subscribe\",\n",
    "  \"Call me\",\n",
    "  \"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\",\n",
    "  \"Only one chance to win CASH! From 100 to 20,000 pounds txt\"\n",
    "  ]\n",
    "\n",
    "def predict_spam(predict_msg):\n",
    "  new_seq = tokenizer.texts_to_sequences(predict_msg)\n",
    "  padded = pad_sequences(new_seq,\n",
    "                         maxlen = max_len,\n",
    "                         padding = padding_type,\n",
    "                         truncating = trunc_type)\n",
    "  return(model.predict(padded))\n",
    "\n",
    "predict_spam(predict_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msg_type\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['msg_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
